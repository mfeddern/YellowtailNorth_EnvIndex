---
title: "LinearModelsEnvPred"
editor: visual
format:
  html:
    toc: true
    html-math-method: katex
    css: styles.css
---


## Background

The northern Yellowtail STAT has identified 3 primary ways that the incorporation and evaluation of environmental indices could be improved upon for the 2025 assessment cycle, these include:

1.  Expand on non-linear relationships considered between recruitment deviations and environmental responses, specifically, evaluate the benefit of using GAMs in addition to quadratic terms.

2.  Compare predictive capacity of models (using Leave-Future-Out cross validation) in addition to model fit.

3.  Consider time-varying relationships (non-stationarity) between environmental conditions and recruitment deviations.

4.  Fitting models to recrutitment deviations from the base model and refitting with an environmental predictor has inherent circularity. Identifying additional indices that can be environmentally informed would benefit the process of developing environmentally informed assessments. These could include indices of juvenile abundance, growth, or maturity.

5.  Methods for index selection currently include fitting all possible model combintations. Issues of multicollinearity and model fitting are challenging across assessment types (i.e. both groundfish and salmon struggle with this). Evaluating additional approaches to deal with both multicollinearity and variable selection that also can deal with extremely limited time series would be beneficial. These can include regularization and machine learning methods.

These efforts are in addition to the work lead by Nick Tolmieri and Amanda Darby which

1.  Generated a ecological profile for Yellowtail north based on life history information

2.  Compared linear models including quadratic terms where aappropriate and omitting highly correlated predictors from the same model

3.  Found the model with the best fit to the data using AIC and principles of parsimony

4.  Evaluated model performance using jack knifing and predicting the last 4 years of data.

## Code set up

First we set up the appropriate packages and references. File paths will be in reference to where the .qmd is saved

```{r}
#| echo: false
#| warning: false
#| message: false


library(bayesdfa)
library(tidyverse)
library(ggplot2)
library(readr) # faster writing
library(data.table) # faster writing of large files
library(lubridate)
library(mgcv)
library(MuMIn)
library(corrplot)
library(car)
library(ggpubr)
library(fst)

source("Src/_00_yellowtail-header.r")
source("Src/Functions-for-envir-index.r")
```

Next we set up the appropriate directories and read in the data.

```{r}
#| echo: false
#| warning: false

df = data.frame(read.csv("data-yellowtail/02_DATA_Combined_glorys_yellowtail.csv"), header = T)
envir_data = df %>%  # drop terms not in model statement
  dplyr::select(!any_of(c('year','sd','Y_rec','ZOOpjuv','ZOOben','DDegg')))
#head(envir_data)
#dim(envir_data)
data_years = 1994:2014


```

We can build the functions including quadratic terms and omitting data that are missing years. We pull out DDegg just so we do not exceed the limit of 31 terms - pulling this out was somewhat arbitrary based on Amandas perliminary results.

```{r}
#| echo: false
#| warning: false

quadratic_terms = c('LSTlarv','ONIpre','ONIlarv', 'CutiSTIpjuv')

form_dredge = make_dredge_equation(envir_data = envir_data, quadratic_vars = quadratic_terms)
form_dredge
data_1 = df %>% 
  dplyr::select(!any_of( c('ZOOpjuv', 'ZOOben', 'DDegg')))  %>% 
  filter(year %in% data_years)


```

## 1. Evaluating multicolinearity and temporal stability of environmental predictors

### Running a DFA

Before we fit models, lets first understand patterns of correlation and covariability across these environmnetal conditions. To start, lets look at a DFA. We find that across time series, there is a strong underlying trend that is predominantly loaded on by temperature time series and represents transport, mixed layer depth, and upwelling are not as well represented. The model struggles to converge with more than one latent trend.

```{r}
#| echo: false
#| warning: false
  #Organize SCC biology ata
dat<- df %>%  # drop terms not in model statement
  dplyr::select(!any_of(c('sd','Y_rec','ZOOpjuv','ZOOben','LUSI')))
dat_red <- dat[complete.cases(dat), ]
dat_scale <-  dat_red%>%
    dplyr::select(!any_of(c('year'))) %>% 
    mutate_all(~ scale(.))%>%
  cbind(year=dat_red$year)
dat<-dat_scale
ax<- 20
ti<-24
wid <- 28
plot_trends2 <- function(rotated_modelfit,
                         years = NULL,
                         highlight_outliers = FALSE,
                         threshold = 0.01) {
  rotated <- rotated_modelfit
  df <- dfa_trends(rotated, years = years)
  
  # make faceted ribbon plot of trends
  p1 <- ggplot(df, aes_string(x = "time", y = "estimate")) +
    geom_ribbon(aes_string(ymin = "lower", ymax = "upper"), alpha = 0.4) +
    geom_line() +
    facet_wrap("trend_number") +
    xlab("Time") +
    ylab("")+
    
    theme(axis.text=element_text(size=ax),
          axis.title=element_text(size=ti,face="bold"))+
    theme_bw()
  
  if (highlight_outliers) {
    swans <- find_swans(rotated, threshold = threshold)
    df$outliers <- swans$below_threshold
    p1 <- p1 + geom_point(data = df[which(df$outliers), ], color = "red")
  }
  
  p1
}


plot_loadings2 <- function(rotated_modelfit,
                           names = NULL,
                           facet = TRUE,
                           violin = TRUE,
                           conf_level = 0.95,
                           threshold = NULL) {
  v <- dfa_loadings(rotated_modelfit,
                    summary = FALSE,
                    names = names,
                    conf_level = conf_level
  )
  df <- dfa_loadings(rotated_modelfit,
                     summary = TRUE,
                     names = names,
                     conf_level = conf_level
  )
  
  # filter values below threshold
  if (!is.null(threshold)) {
    df <- df[df$prob_diff0 >= threshold, ]
    v <- v[v$prob_diff0 >= threshold, ]
  }
  
  if (!violin) {
    p1 <- ggplot(df, aes_string(
      x = "name", y = "median", col = "trend",
      alpha = "prob_diff0"
    )) +
      geom_point(size = 3, position = position_dodge(0.3)) +
      geom_errorbar(aes_string(ymin = "lower", ymax = "upper"),
                    position = position_dodge(0.3), width = 0
      ) +
      geom_hline(yintercept = 0, lty = 2) +
      coord_flip() +
      xlab("Time Series") +
      ylab("Loading")+
      guides(fill="none", alpha='none')+
      scale_x_discrete(labels = function(x) str_wrap(x, width = wid))+
      theme(legend.position="none")+
      theme_bw()
  }
  
  if (violin) {
    p1 <- ggplot(v, aes_string(
      x = "name", y = "loading", fill = "trend",
      alpha = "prob_diff0"
    )) +
      geom_violin(color = NA) +
      geom_hline(yintercept = 0, lty = 2) +
      coord_flip() +
      xlab("Time Series") +
      ylab("Loading")+
      theme(axis.text=element_text(size=ax),
            axis.title=element_text(size=ti,face="bold"))+
      guides(fill="none", alpha='none')+
      scale_x_discrete(labels = function(x) str_wrap(x, width = wid))+
      theme_bw()
  }
  
  if (facet) {
    p1 <- p1 + facet_wrap(~trend, scales = "free_x")
  }
  
  p1
}


y1calcofi <- 1994
y2calcofi<- 2021
n1 <- names(dat)[2:26]
dat.calcofi<-dat%>%select(c(year,n1)) #just setting an order so we know how to set the variance index for each survey
remelt = melt(dat.calcofi,id.vars = "year")
names(remelt)<-c("year","variable","value")
Y <- dcast(remelt, variable ~ year)
names = Y$variable
Y = as.matrix(Y[,-which(names(Y) == "variable")])

n_chains = 3
n_iter = 8000

options(mc.cores = parallel::detectCores())

# load environmental covariate data, and average over spring months to have one value per covar per year
nspp=dim(Y)[1]
nyear=dim(Y)[2]
ntrend=1
n_row=nspp*nyear
n_row_pro=ntrend*nyear

model_df = expand.grid(estimate_trend_ma = FALSE,
                       estimate_trend_ar = TRUE, est_nu = TRUE, estimate_process_sigma = c(FALSE),
                       var_index = c("survey"), num_trends = 1,
                       elpd_loo = TRUE, se_elpd_loo=NA)
namescalcofi<-data.frame(names)
varIndx = c(rep(1,length(n1)))
fit.mod.calcofi<-readRDS('fit.mod.calcofi.rds')
r.calcofi <- rotate_trends(fit.mod.calcofi)
p.calcofi <- plot_trends2(r.calcofi,years =dat.calcofi$year)
l.calcofi <- plot_loadings2(r.calcofi,names=namescalcofi$names)


#is_converged(fit.mod.calcofi)
#summary(fit.mod.calcofi)
arranged <- ggarrange(p.calcofi, l.calcofi,ncol = 2, nrow = 1,
                      heights=c(1,1.25,1.5))
arranged

dfa_trend<-cbind(dfa=c(r.calcofi$trends_mean), year=dat.calcofi$year)
write.csv(dfa_trend, "data-yellowtail/dfa_trend.csv")

```

### Assessing the weight of support for each predictor as a function of time series length

Next we can look at the weight of evidence in support for each time series and consider how this might change based on the observed time period of recruitment deviations. For this approach we will dredge up to 5 covariates, we will consider quadratic terms, and omit combinations of highly correlated covariates. This is not to expressly identify "THE" model but as an exercise to identify the most important variables, and potential non-stationarities in that relationship. To fit these models we will use at least 10 years of data (1994 - 2004) and iteratively add in one year of data and refit the model set. Colors denote the over all aic weight across all models with that variable.

Two variables stand out, CUTI spring transition as a non-linear (quadratic) relationship and ONI during the preconditioning time period. Notably, the weight of evidence for a single time series really diminshes when when the model is fit to 1994 - 2011:2014 such that AIC is fairly distributed across time series.

```{r}
#| echo: false
#| warning: false
timevarying_dredge<- readRDS("timevarying_dredge.rds")

p <- ggplot(timevarying_dredge%>%filter(last_year <= 2014), aes(as.factor(last_year), variable, fill= value)) + 
  xlab("Last Year")+
  scale_fill_gradient(low = "white", high = "Darkgreen") +
  geom_tile()
p 

```

If we try to fit a model that is highly parsimonious, by fitting only 1 covariate at a time in the same framework (or selecting the most parsimonious model) we get a different answer and find that Mixed layer depth during the larval lifestage is the most important. I find this result interesting because MLDlarv does not load onto our DFA significantly. Given all of this variability, its worth exploring these different models a bit more.

```{r}
#| echo: false
#| warning: false
timevarying_dredge_01<- readRDS("timevarying_dredge_singlecov.rds")

p <- ggplot(timevarying_dredge_01%>%filter(last_year <= 2014), aes(as.factor(last_year), variable, fill= value)) + 
  xlab("Last Year")+
  scale_fill_gradient(low = "white", high = "Darkgreen") +
  geom_tile()
p 

```

### Assessing model selection based on AIC and principles of parsimony

Lets take a look at what the best models from Amanda and Nicks workflow looks like. If we assign the best model as the model with the lowest AIC we also identify the MLDlarv model. However, this model has an extremely low R\^2 and also does not fit the most recent half of the time series.

```{r}
#| echo: false
#| warning: false
mtable = readRDS('results-yellowtail/Table_dredge-model-fits.rds')
best_fit = find_best_fit(mtable, fewest_params=TRUE)
bf_mod = bf_mod_equation(best_fit)
df_index = predict_best_fit(old_data=data_1, new_data=df, bf_mod=bf_mod)

ggplot(df_index, aes(x=year, y=fit)) + 
  geom_ribbon(data=df_index, aes(ymin = fit-1.96*se, ymax = fit+1.96*se), 
              color='grey', alpha = 0.05) + 
  geom_line() + 
  ggtitle(bf_mod,paste("R2 =", round(best_fit$R2, 2)))+
  xlab("Year") + ylab('ln (rec devs)') + 
  geom_point(aes(year,Y_rec)) + 
  scale_x_continuous(breaks=seq(1995,2025,5) , minor_breaks = 1993:max(df$year)) + 
  annotate(geom='segment', x=1993, xend=max(df_index$year), y=0, linetype='dotted') +
  theme_bw()

```

Now what if we relax teh requirement of having the most parsimonious model and instead focus on the best fit across the entire time series, we find the best model is CUTI STI with a quadratic term.

```{r}
#| echo: false
#| warning: false
best_fit = find_best_fit(mtable, fewest_params=FALSE)
bf_mod = bf_mod_equation(best_fit)
df_index = predict_best_fit(old_data=data_1, new_data=df, bf_mod=bf_mod)

ggplot(df_index, aes(x=year, y=fit)) + 
  geom_ribbon(data=df_index, aes(ymin = fit-1.96*se, ymax = fit+1.96*se), 
              color='grey', alpha = 0.05) + 
  geom_line() + 
  ggtitle(bf_mod,paste("R2 =", round(best_fit$R2, 2)))+
  xlab("Year") + ylab('ln (rec devs)') + 
  geom_point(aes(year,Y_rec)) + 
  scale_x_continuous(breaks=seq(1995,2025,5) , minor_breaks = 1993:max(df$year)) + 
  annotate(geom='segment', x=1993, xend=max(df_index$year), y=0, linetype='dotted') +
  theme_bw()


```

We can also look at a table of the best models. It becomes very apparent the top models include CUTI STI as a non-linear term, and the models that include it have much better R\^2 values.

```{r}
#| echo: false
#| warning: false
mtable2 = round(data.frame(subset(mtable, delta<2)),2)
mtable_best<-mtable2%>%select(CutiSTIpjuv,I.CutiSTIpjuv.2.,DDpre,HCIlarv,MLDlarv,Tcop,R2,AICc,delta)
rownames(mtable_best) <- NULL
knitr::kable(mtable_best, format="html")

```

### Considering correlation across covariates with the strongest weights of evidence

Using the first framework we look at, we can take the entire time series through 2014, and look at what predictors have the most evidence of support. Lets say that we only want to look at predictors that have at least 15% of the model support for the full time series. Looking at the data this way, the covariates that have the best weight of evidence are: long shore transport (larv), ONI (pelagic juveniles, larval, and preconditioning), CUTI STI, degree days benthic juveniles, and mixed layer depth larval.

```{r}
#| echo: false
#| warning: false
knitr::kable(timevarying_dredge_01%>%filter(last_year==2014&value>0.15), format="html")

```

Thinking about the variables with the most weight of evidence, we can test out a backwards selection technique. Instead of AIC (which is prone to overfitting and we already know these variables have AIC support) we can use VIF to try and avoid multicollinerity. Lets start with the model that is saturated with the variables that have strong AIC support.

```{r}
#| echo: false
#| warning: false

the_lm <-  lm(Y_rec ~  LSTlarv + ONIpjuv + ONIlarv + 
    ONIpre  + CutiSTIpjuv + MLDpjuv + DDben, data=data_1)

round(vif(the_lm), 2)

lm_sat <-data_1%>%select(LSTlarv, ONIpjuv,ONIlarv,ONIpre,CutiSTIpjuv, MLDpjuv, DDben)
corrplotsat<-cor(lm_sat)
corrplot.mixed(corrplotsat)

```

ONIlarv is correlated with a bunch of covariates. Lets ditch it.

```{r}
#| echo: false
#| warning: false

the_lm2 <-  lm(Y_rec ~  LSTlarv + ONIpjuv + 
    ONIpre  + CutiSTIpjuv + MLDpjuv + DDben, data=data_1)

round(vif(the_lm2), 2)

lm2 <-data_1%>%select(LSTlarv, ONIpjuv,ONIpre,CutiSTIpjuv, MLDpjuv, DDben)
corrplotsat<-cor(lm2)
corrplot.mixed(corrplotsat)

```

And finally, what does this model look like? We get a slightly worse fit than just using upwelling, and we still struggle with overestimating recruitment when it is low (the negative values)

```{r}
#| echo: false
#| warning: false
the_lm2 <-  lm(Y_rec ~  LSTlarv + ONIpjuv + 
    ONIpre  + CutiSTIpjuv+I(CutiSTIpjuv^2) + MLDpjuv + DDben, data=data_1)
bf_mod = eval(the_lm2$call[[2]])
#summary(the_lm2)
df_index = predict_best_fit(old_data=data_1, new_data=df, bf_mod=bf_mod)

ggplot(df_index, aes(x=year, y=fit)) + 
  geom_ribbon(data=df_index, aes(ymin = fit-1.96*se, ymax = fit+1.96*se), 
              color='grey', alpha = 0.05) + 
  geom_line() + 
  ggtitle(bf_mod,paste("R2 =", 0.40))+
  xlab("Year") + ylab('ln (rec devs)') + 
  geom_point(aes(year,Y_rec)) + 
  scale_x_continuous(breaks=seq(1995,2025,5) , minor_breaks = 1993:max(df$year)) + 
  annotate(geom='segment', x=1993, xend=max(df_index$year), y=0, linetype='dotted') +
  theme_bw()



```

We don't want to use DFA latent trends as predictors because they lack transparency and interpretability - but lets look at it...it is GARBAGE. Why? Likely because it is dominated by temperature and not influenced by the transport, upwelling and mixed layer depth variables that provide better fits. Therefore, even using a DFA would require some degree of covariate exploration for any explanatory power or predictive ability.

```{r}
#| echo: false
#| warning: false

data_2 = data.frame(trend=c(r.calcofi$trends_median), year=seq(1994,2014+7))%>%
  left_join(data_1)
lm_dfa<-lm(Y_rec ~trend, data=data_2%>%filter(year>=1994&year<=2014))

df_index = predict_best_fit(old_data=data_2%>%filter(year>=1994&year<=2014), new_data=data_2, bf_mod=lm_dfa)
bf_mod = eval(lm_dfa$call[[2]])


ggplot(df_index, aes(x=year, y=fit)) + 
  geom_ribbon(data=df_index, aes(ymin = fit-1.96*se, ymax = fit+1.96*se), 
              color='grey', alpha = 0.05) + 
  geom_line() + 
  ggtitle(bf_mod,paste("R2 =", round(summary(lm_dfa)$r.squared,3)))+
  xlab("Year") + ylab('ln (rec devs)') + 
  geom_point(aes(year,Y_rec)) + 
  scale_x_continuous(breaks=seq(1995,2025,5) , minor_breaks = 1993:max(df$year)) + 
  annotate(geom='segment', x=1993, xend=max(df_index$year), y=0, linetype='dotted') +
  theme_bw()



```

The fact that the correlation between CUTI STI and yellowtail rec devs changes in 2010/2011 is suspicious given it is modeled from ROMS data and ROMS models also changed over that period. To evaluate whether this is this may be the cause of the change we looked at the time series of CUTI STI along with comparing it to Bakun derived STI to see if Bakun indices offer a reasonable alternative that may not be subject to changes in ROMS around 2010. CUTI and Bakun STI are only moderately correlated (0.52) and we don't find that there are significant differences in CUTI STI before and after 2010. Mike Jacox confirmed that there the wind data that CUTI is derived from should be stable from ROMs from at least 2000 onward. He also said he may have CUTI from GLORYs somewhere on his computer (need to follow up).

From Kiva: "I included all years of "main" recruitment deviations. I would say the information quality goes down around 2010-2011, but you could use anything for playing around." This may partially explain the lack of consistency after 2010/2011

```{r}
#| echo: false
#| warning: false

data_3<-data_2%>%select(year,bakun_sti, CutiSTIpjuv)%>%
  pivot_longer(cols=c(bakun_sti, CutiSTIpjuv),names_to = "upwelling", values_to = "index")



ggplot(data_3, aes(x=year, y=index, group=upwelling, col=upwelling)) + 
  geom_line(lwd=1) +
  theme_bw()

up<-read.csv('data-yellowtail/upwellingts.csv')
cor(up%>%select(CutiSTIpjuv,bakun_sti))

up2<-up%>%
  pivot_longer(cols=c(bakun_sti, CutiSTIpjuv),names_to = "upwelling", values_to = "index")

ggplot(up2, aes(x=year, y=index, group=upwelling, col=upwelling)) + 
  geom_line(lwd=1) +
  theme_bw()

up<-up%>%
  mutate(ROMS=ifelse(year<=2010, 'early','late'))

summary(lm(CutiSTIpjuv~ROMS,data=up))
#summary(lm(CutiSTIpjuv~year,data=up))
```

## Univariate GAMs

Here I fit univariate GAMs to evaluate the differences in AIC, Leave-One-Out Cross Validation, and Leave-Future-Out Cross Validation. The goal of this preliminary analysis before fitting multivariate GAMs was to examine more closely how different variables perform with particular attention to fits versus predictive capacity. Plotting model fits with a single variable is usedful for understanding which patterns in the data are explained by each variable.

First, lets look at which models have the most support based on a) AIC, b) LOO-CV, and c) LFO-CV.

```{r}
#| echo: false
#| warning: false

univariateGAM_Results= data.frame(read.csv("univariateGAM_Results.csv"))%>%
  select(var, RMSE_LOO, RMSE_LFO,AIC_LOO,rsq_LOO,rsq_LFO,dev.ex_LOO,dev.ex_LFO)

knitr::kable(arrange(data.frame(univariateGAM_Results),RMSE_LOO), format="html")
knitr::kable(arrange(data.frame(univariateGAM_Results),RMSE_LFO), format="html")
```

We find that the models supported with AIC and LOO-CV are very consistent and agree with the linear models, but LFO-CV is a bit of a mess. Lets look at the model fits for the full time series:

```{r, fig.width=11, fig.height=8}
#| echo: false
#| warning: false

univariateGAM_Fits= data.frame(read.csv("univariateGAM_Fits.csv"))

g2 <- ggplot(univariateGAM_Fits%>%filter(Type=="fitted"), aes(year,fitted_LFO)) +
  geom_line() +
    geom_ribbon(aes(x=fitted_LFO, y=fitted_LFO, ymax=fitted_LFO+sd, ymin=fitted_LFO-sd), 
              alpha=0.2)+
  geom_point(data=univariateGAM_Fits%>%filter(Type=="predicted"),aes(x=year,y=Y_Rec),col="red") +
  geom_point(aes(y=Y_Rec))+
  geom_line(data=univariateGAM_Fits%>%filter(Type=="predicted"),aes(x=year,y=fitted_LFO,col="red"))+
  facet_wrap(~ var, scale="free_x") +
  theme_bw() +
  xlab("Year") + ylab("Fitted") +
  xlim(1993,2014)+
  theme(strip.text = element_text(size=6),
        strip.background = element_rect(fill="white"))
g2 

```

Looking at this, it becomes pretty obvious that the variables with the most support are not necessarily the ones that predict whether recruitment will be above or below average in the last few years, but rather the ones that just go in the middle of a bunch of points that are centered close to the mean. No variable does a great job predicting 2010, but CUTI STI, BEUTI STI, and ONI pre at least capture some patterns in below average.


## Next steps

1.  Fit GAMs with temporally stable relationships (status: **done**)

2.  Perform model selection using LFO-CV (status: **done**)

3. Evaluate marginal improvement of RMSE for multivariate GAMs and LMs (status: **done**)

4.  Evaluate non-stationary relationships between recruitment deviations and the environmental predictors with the most support to assess non-stationarity (status: **in development**)

5. Develop a method for a rolling window LFO-CV to address and test challenged outlined above (status: **in development**)

6.  Fit models using regularization techniques (status: **to do**)

7.  Fit models using machine learning techniques (status: **to do, low priority**)
